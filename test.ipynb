{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 22 19:37:56 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.89.02    Driver Version: 525.89.02    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-PCI...  Off  | 00000000:01:00.0 Off |                    0 |\n",
      "| N/A   36C    P0    36W / 250W |  22723MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-PCI...  Off  | 00000000:24:00.0 Off |                    0 |\n",
      "| N/A   28C    P0    35W / 250W |  12123MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100-PCI...  Off  | 00000000:41:00.0 Off |                    0 |\n",
      "| N/A   27C    P0    34W / 250W |      3MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100-PCI...  Off  | 00000000:61:00.0 Off |                    0 |\n",
      "| N/A   27C    P0    34W / 250W |      3MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA A100-PCI...  Off  | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   25C    P0    34W / 250W |      3MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA A100-PCI...  Off  | 00000000:A1:00.0 Off |                    0 |\n",
      "| N/A   25C    P0    32W / 250W |      3MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA A100-PCI...  Off  | 00000000:C1:00.0 Off |                    0 |\n",
      "| N/A   25C    P0    32W / 250W |      3MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA A100-PCI...  Off  | 00000000:E1:00.0 Off |                    0 |\n",
      "| N/A   24C    P0    33W / 250W |      3MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    1   N/A  N/A   1501395      C   .../jax_torch_env/bin/python    12120MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "!echo $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logging improved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/home/nstracke/miniconda3/envs/control/lib/python3.8/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
      "/export/home/nstracke/miniconda3/envs/control/lib/python3.8/site-packages/torch/utils/tensorboard/__init__.py:6: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  ) < LooseVersion(\"1.15\"):\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from torch.utils.data import DataLoader\n",
    "from custom_dataset_cross import MyDataset\n",
    "import cv2\n",
    "from share import *\n",
    "import torchvision\n",
    "import einops\n",
    "import numpy as np\n",
    "from ldm.modules.encoders.modules import FrozenClipImageEmbedder\n",
    "import torch.nn.functional as F\n",
    "import config\n",
    "import gradio as gr\n",
    "import random\n",
    "import torch\n",
    "from PIL import Image\n",
    "from pytorch_lightning import seed_everything\n",
    "from annotator.util import resize_image, HWC3\n",
    "from cldm.model import create_model, load_state_dict\n",
    "from cldm.ddim_hacked import DDIMSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 64401\n"
     ]
    }
   ],
   "source": [
    "seed = -1\n",
    "if seed == -1:\n",
    "    seed = random.randint(0, 65535)\n",
    "seed_everything(seed)\n",
    "\n",
    "if config.save_memory:\n",
    "    model.low_vram_shift(is_diffusing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(name: str):\n",
    "    name = name.split('.')[1] \n",
    "    name = name.split('_')[-1]\n",
    "    name = name[3:]\n",
    "    return int(name)\n",
    "\n",
    "def get_sequence():\n",
    "    for batch in dataloader:\n",
    "        meta_batch = batch['meta']['file_name']\n",
    "        meta = meta_batch[0]\n",
    "        meta = meta.split('/')[1]\n",
    "        meta = meta.split('_')[:-1]\n",
    "        meta = '_'.join(meta)\n",
    "        print(meta)\n",
    "        styles = glob.glob('./data/kin_hed2/jpg/' + meta + '*')\n",
    "        styles.sort(key=get_key)\n",
    "        structures = glob.glob('./data/kin_hed2/hint/' + meta + '*')\n",
    "        structures.sort(key=get_key)\n",
    "        print(styles)\n",
    "        print(structures)\n",
    "        return styles, structures\n",
    "\n",
    "def get_img(path):\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # img = img.astype(np.float32) / 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grid(batch, length, path):\n",
    "    grid = torchvision.utils.make_grid(batch, nrow=length)\n",
    "    grid = grid.transpose(0, 1).transpose(1, 2).squeeze(-1)\n",
    "    grid = grid.cpu().numpy().clip(0, 255).astype(np.uint8)\n",
    "    Image.fromarray(grid).save(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset('kin_hed2')\n",
    "dataloader = DataLoader(dataset, num_workers=16, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/home/nstracke/miniconda3/envs/control/lib/python3.8/site-packages/torch/distributed/_sharded_tensor/__init__.py:8: DeprecationWarning: torch.distributed._sharded_tensor will be deprecated, use torch.distributed._shard.sharded_tensor instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ControlLDM: Running in eps-prediction mode\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n",
      "DiffusionWrapper has 859.52 M params.\n",
      "making attention of type 'vanilla-xformers' with 512 in_channels\n",
      "building MemoryEfficientAttnBlock with 512 in_channels...\n",
      "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
      "making attention of type 'vanilla-xformers' with 512 in_channels\n",
      "building MemoryEfficientAttnBlock with 512 in_channels...\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
      "Loaded model config from [./models/cldm_v15_org.yaml]\n",
      "Loaded state_dict from [./train_log/kin_hed_2/lightning_logs/version_0/checkpoints/epoch=1-step=119930.ckpt]\n",
      "loading model 2...\n",
      "ControlLDM: Running in eps-prediction mode\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n",
      "DiffusionWrapper has 859.52 M params.\n",
      "making attention of type 'vanilla-xformers' with 512 in_channels\n",
      "building MemoryEfficientAttnBlock with 512 in_channels...\n",
      "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
      "making attention of type 'vanilla-xformers' with 512 in_channels\n",
      "building MemoryEfficientAttnBlock with 512 in_channels...\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
      "Loaded model config from [./models/cldm_v15_cross.yaml]\n",
      "Loaded state_dict from [./train_log/kin_hed_cross_3/lightning_logs/version_0/checkpoints/epoch=4-step=412223.ckpt]\n"
     ]
    }
   ],
   "source": [
    "p1 = './train_log/kin_hed_2/lightning_logs/version_0/checkpoints/epoch=1-step=119930.ckpt'\n",
    "p2 = './train_log/kin_hed_cross_3/lightning_logs/version_0/checkpoints/epoch=4-step=412223.ckpt'\n",
    "\n",
    "print('loading model 1...')\n",
    "model = create_model('./models/cldm_v15_org.yaml').cpu()\n",
    "model.load_state_dict(load_state_dict(p1, location='cuda'))\n",
    "model = model.cuda()\n",
    "\n",
    "print('loading model 2...')\n",
    "model2 = create_model('./models/cldm_v15_cross.yaml').cpu()\n",
    "model2.load_state_dict(load_state_dict(p2, location='cuda'))\n",
    "model2 = model.cuda()\n",
    "\n",
    "\n",
    "\n",
    "ddim_sampler = DDIMSampler(model)\n",
    "frozenClipImageEmbedder = FrozenClipImageEmbedder()\n",
    "frozenClipImageEmbedder = frozenClipImageEmbedder.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fEkBAEqJXWk_000021_000031\n",
      "['./data/kin_hed2/jpg/fEkBAEqJXWk_000021_000031_idx0.png', './data/kin_hed2/jpg/fEkBAEqJXWk_000021_000031_idx500.png', './data/kin_hed2/jpg/fEkBAEqJXWk_000021_000031_idx1000.png', './data/kin_hed2/jpg/fEkBAEqJXWk_000021_000031_idx1500.png', './data/kin_hed2/jpg/fEkBAEqJXWk_000021_000031_idx2000.png']\n",
      "['./data/kin_hed2/hint/fEkBAEqJXWk_000021_000031_idx500.png', './data/kin_hed2/hint/fEkBAEqJXWk_000021_000031_idx1000.png', './data/kin_hed2/hint/fEkBAEqJXWk_000021_000031_idx1500.png', './data/kin_hed2/hint/fEkBAEqJXWk_000021_000031_idx2000.png']\n",
      "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0\n",
      "Running DDIM Sampling with 40 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 40/40 [00:16<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0\n",
      "Running DDIM Sampling with 40 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 40/40 [00:16<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QgIXLpEwuLM_000015_000025\n",
      "['./data/kin_hed2/jpg/QgIXLpEwuLM_000015_000025_idx0.png', './data/kin_hed2/jpg/QgIXLpEwuLM_000015_000025_idx500.png', './data/kin_hed2/jpg/QgIXLpEwuLM_000015_000025_idx1000.png', './data/kin_hed2/jpg/QgIXLpEwuLM_000015_000025_idx1500.png', './data/kin_hed2/jpg/QgIXLpEwuLM_000015_000025_idx2000.png']\n",
      "['./data/kin_hed2/hint/QgIXLpEwuLM_000015_000025_idx500.png', './data/kin_hed2/hint/QgIXLpEwuLM_000015_000025_idx1000.png', './data/kin_hed2/hint/QgIXLpEwuLM_000015_000025_idx1500.png', './data/kin_hed2/hint/QgIXLpEwuLM_000015_000025_idx2000.png']\n",
      "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0\n",
      "Running DDIM Sampling with 40 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 40/40 [00:16<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0\n",
      "Running DDIM Sampling with 40 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 40/40 [00:16<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ikSO8zcJf50_000805_000815\n",
      "['./data/kin_hed2/jpg/ikSO8zcJf50_000805_000815_idx0.png', './data/kin_hed2/jpg/ikSO8zcJf50_000805_000815_idx500.png', './data/kin_hed2/jpg/ikSO8zcJf50_000805_000815_idx1000.png', './data/kin_hed2/jpg/ikSO8zcJf50_000805_000815_idx1500.png', './data/kin_hed2/jpg/ikSO8zcJf50_000805_000815_idx2000.png']\n",
      "['./data/kin_hed2/hint/ikSO8zcJf50_000805_000815_idx500.png', './data/kin_hed2/hint/ikSO8zcJf50_000805_000815_idx1000.png', './data/kin_hed2/hint/ikSO8zcJf50_000805_000815_idx1500.png', './data/kin_hed2/hint/ikSO8zcJf50_000805_000815_idx2000.png']\n",
      "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0\n",
      "Running DDIM Sampling with 40 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 40/40 [00:16<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0\n",
      "Running DDIM Sampling with 40 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 40/40 [00:16<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EgcOG7IsRTA_000004_000014\n",
      "['./data/kin_hed2/jpg/EgcOG7IsRTA_000004_000014_idx0.png', './data/kin_hed2/jpg/EgcOG7IsRTA_000004_000014_idx500.png', './data/kin_hed2/jpg/EgcOG7IsRTA_000004_000014_idx1000.png', './data/kin_hed2/jpg/EgcOG7IsRTA_000004_000014_idx1500.png']\n",
      "['./data/kin_hed2/hint/EgcOG7IsRTA_000004_000014_idx500.png', './data/kin_hed2/hint/EgcOG7IsRTA_000004_000014_idx1000.png', './data/kin_hed2/hint/EgcOG7IsRTA_000004_000014_idx1500.png']\n",
      "Data shape for DDIM sampling is (3, 4, 64, 64), eta 0\n",
      "Running DDIM Sampling with 40 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 40/40 [00:13<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is (3, 4, 64, 64), eta 0\n",
      "Running DDIM Sampling with 40 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 40/40 [00:13<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74mcszTab-E_000699_000709\n",
      "['./data/kin_hed2/jpg/74mcszTab-E_000699_000709_idx0.png', './data/kin_hed2/jpg/74mcszTab-E_000699_000709_idx500.png', './data/kin_hed2/jpg/74mcszTab-E_000699_000709_idx1000.png', './data/kin_hed2/jpg/74mcszTab-E_000699_000709_idx1500.png', './data/kin_hed2/jpg/74mcszTab-E_000699_000709_idx2000.png']\n",
      "['./data/kin_hed2/hint/74mcszTab-E_000699_000709_idx500.png', './data/kin_hed2/hint/74mcszTab-E_000699_000709_idx1000.png', './data/kin_hed2/hint/74mcszTab-E_000699_000709_idx1500.png', './data/kin_hed2/hint/74mcszTab-E_000699_000709_idx2000.png']\n",
      "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0\n",
      "Running DDIM Sampling with 40 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 40/40 [00:16<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0\n",
      "Running DDIM Sampling with 40 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 40/40 [00:16<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WO9DEeddDvk_000003_000013\n",
      "['./data/kin_hed2/jpg/WO9DEeddDvk_000003_000013_idx0.png', './data/kin_hed2/jpg/WO9DEeddDvk_000003_000013_idx500.png', './data/kin_hed2/jpg/WO9DEeddDvk_000003_000013_idx1000.png', './data/kin_hed2/jpg/WO9DEeddDvk_000003_000013_idx1500.png', './data/kin_hed2/jpg/WO9DEeddDvk_000003_000013_idx2000.png']\n",
      "['./data/kin_hed2/hint/WO9DEeddDvk_000003_000013_idx500.png', './data/kin_hed2/hint/WO9DEeddDvk_000003_000013_idx1000.png', './data/kin_hed2/hint/WO9DEeddDvk_000003_000013_idx1500.png', './data/kin_hed2/hint/WO9DEeddDvk_000003_000013_idx2000.png']\n",
      "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0\n",
      "Running DDIM Sampling with 40 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 40/40 [00:16<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0\n",
      "Running DDIM Sampling with 40 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 40/40 [00:16<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HVTokfdNQd0_000005_000015\n",
      "['./data/kin_hed2/jpg/HVTokfdNQd0_000005_000015_idx0.png', './data/kin_hed2/jpg/HVTokfdNQd0_000005_000015_idx500.png', './data/kin_hed2/jpg/HVTokfdNQd0_000005_000015_idx1000.png', './data/kin_hed2/jpg/HVTokfdNQd0_000005_000015_idx1500.png', './data/kin_hed2/jpg/HVTokfdNQd0_000005_000015_idx2000.png']\n",
      "['./data/kin_hed2/hint/HVTokfdNQd0_000005_000015_idx500.png', './data/kin_hed2/hint/HVTokfdNQd0_000005_000015_idx1000.png', './data/kin_hed2/hint/HVTokfdNQd0_000005_000015_idx1500.png', './data/kin_hed2/hint/HVTokfdNQd0_000005_000015_idx2000.png']\n",
      "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0\n",
      "Running DDIM Sampling with 40 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 40/40 [00:16<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0\n",
      "Running DDIM Sampling with 40 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 40/40 [00:16<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_oHPNo02obI_000315_000325\n",
      "['./data/kin_hed2/jpg/_oHPNo02obI_000315_000325_idx0.png', './data/kin_hed2/jpg/_oHPNo02obI_000315_000325_idx500.png', './data/kin_hed2/jpg/_oHPNo02obI_000315_000325_idx1000.png', './data/kin_hed2/jpg/_oHPNo02obI_000315_000325_idx1500.png', './data/kin_hed2/jpg/_oHPNo02obI_000315_000325_idx2000.png']\n",
      "['./data/kin_hed2/hint/_oHPNo02obI_000315_000325_idx500.png', './data/kin_hed2/hint/_oHPNo02obI_000315_000325_idx1000.png', './data/kin_hed2/hint/_oHPNo02obI_000315_000325_idx1500.png', './data/kin_hed2/hint/_oHPNo02obI_000315_000325_idx2000.png']\n",
      "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0\n",
      "Running DDIM Sampling with 40 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 40/40 [00:16<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0\n",
      "Running DDIM Sampling with 40 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 40/40 [00:16<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kaaGCkso_GQ_000203_000213\n",
      "['./data/kin_hed2/jpg/kaaGCkso_GQ_000203_000213_idx0.png', './data/kin_hed2/jpg/kaaGCkso_GQ_000203_000213_idx500.png', './data/kin_hed2/jpg/kaaGCkso_GQ_000203_000213_idx1000.png', './data/kin_hed2/jpg/kaaGCkso_GQ_000203_000213_idx1500.png', './data/kin_hed2/jpg/kaaGCkso_GQ_000203_000213_idx2000.png']\n",
      "['./data/kin_hed2/hint/kaaGCkso_GQ_000203_000213_idx500.png', './data/kin_hed2/hint/kaaGCkso_GQ_000203_000213_idx1000.png', './data/kin_hed2/hint/kaaGCkso_GQ_000203_000213_idx1500.png', './data/kin_hed2/hint/kaaGCkso_GQ_000203_000213_idx2000.png']\n",
      "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0\n",
      "Running DDIM Sampling with 40 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 40/40 [00:16<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0\n",
      "Running DDIM Sampling with 40 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 40/40 [00:16<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDjZzu0bpaU_000002_000012\n",
      "['./data/kin_hed2/jpg/HDjZzu0bpaU_000002_000012_idx0.png', './data/kin_hed2/jpg/HDjZzu0bpaU_000002_000012_idx500.png', './data/kin_hed2/jpg/HDjZzu0bpaU_000002_000012_idx1000.png', './data/kin_hed2/jpg/HDjZzu0bpaU_000002_000012_idx1500.png', './data/kin_hed2/jpg/HDjZzu0bpaU_000002_000012_idx2000.png']\n",
      "['./data/kin_hed2/hint/HDjZzu0bpaU_000002_000012_idx500.png', './data/kin_hed2/hint/HDjZzu0bpaU_000002_000012_idx1000.png', './data/kin_hed2/hint/HDjZzu0bpaU_000002_000012_idx1500.png', './data/kin_hed2/hint/HDjZzu0bpaU_000002_000012_idx2000.png']\n",
      "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0\n",
      "Running DDIM Sampling with 40 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 40/40 [00:16<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0\n",
      "Running DDIM Sampling with 40 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 40/40 [00:16<00:00,  2.38it/s]\n"
     ]
    }
   ],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=4\n",
    "\n",
    "ddim_steps = 40\n",
    "strength = 1\n",
    "eta = 0\n",
    "\n",
    "for idx in range(10):\n",
    "    styles, structures = get_sequence()\n",
    "    styles = np.array([get_img(style) for style in styles])\n",
    "    styles = styles.copy().astype(np.float32)\n",
    "\n",
    "    structures = np.array([get_img(structure) for structure in structures])\n",
    "    structures = structures.astype(np.float32) / 255.0\n",
    "\n",
    "    B, H, W, C = structures.shape\n",
    "    shape = (4, H // 8, W // 8)\n",
    "\n",
    "\n",
    "    control = torch.from_numpy(structures.copy()).float().cuda()\n",
    "    control = einops.rearrange(control, 'b h w c -> b c h w')\n",
    "\n",
    "    style = frozenClipImageEmbedder(styles)\n",
    "    c_style = style.last_hidden_state\n",
    "    c_embed = style.pooler_output  \n",
    "\n",
    "    uc_style =  c_style # torch.zeros_like(c_style) #\n",
    "    uc_embed = c_embed\n",
    "\n",
    "    # 11111111111111111111111111111111\n",
    "\n",
    "    scale = 2\n",
    "\n",
    "\n",
    "    cond = {\"c_concat\": [control], \"c_crossattn\": [model.get_learned_conditioning([\"a professional, detailed, high-quality image\"]*B)], \"c_style\": [c_style], \"c_embed\": [c_embed] }\n",
    "    un_cond = {\"c_concat\": [control], \"c_crossattn\": [model.get_learned_conditioning(['']*B)], \"c_style\": [uc_style], \"c_embed\": [uc_embed]  }\n",
    "\n",
    "    model.control_scales =  ([strength] * 13)  # Magic number. ID\n",
    "    samples, intermediates = ddim_sampler.sample(ddim_steps, B,\n",
    "                                                shape, cond, verbose=False, eta=eta,\n",
    "                                                unconditional_guidance_scale=scale,\n",
    "                                                unconditional_conditioning=un_cond)\n",
    "\n",
    "    x_samples = model.decode_first_stage(samples)\n",
    "    x_samples = x_samples * 127.5 + 127.5\n",
    "    # ==========================================\n",
    "\n",
    "    # 2222222222222222222222222222222222222\n",
    "\n",
    "    scale = 2\n",
    "\n",
    "    cond = {\"c_concat\": [control], \"c_crossattn\": [model2.get_learned_conditioning([\"a professional, detailed, high-quality image\"]*B)], \"c_style\": [c_style], \"c_embed\": [c_embed] }\n",
    "    un_cond = {\"c_concat\": [control], \"c_crossattn\": [model2.get_learned_conditioning(['']*B)], \"c_style\": [uc_style], \"c_embed\": [uc_embed]  }\n",
    "\n",
    "    model2.control_scales =  ([strength] * 13)  # Magic number. ID\n",
    "    samples, intermediates = ddim_sampler.sample(ddim_steps, B,\n",
    "                                                shape, cond, verbose=False, eta=eta,\n",
    "                                                unconditional_guidance_scale=scale,\n",
    "                                                unconditional_conditioning=un_cond)\n",
    "\n",
    "    x_samples2 = model2.decode_first_stage(samples)\n",
    "    x_samples2 = x_samples2 * 127.5 + 127.5\n",
    "    # ==========================================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ss = einops.rearrange(styles, 'b h w c -> b c h w')\n",
    "    ss = ss[1:]\n",
    "    ss = torch.Tensor(ss)\n",
    "    ss = ss.cuda()\n",
    "    path = 'vid_check/' + str(idx) + '.jpg'\n",
    "    make_grid(torch.cat((ss, x_samples, x_samples2)), B, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "control",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
